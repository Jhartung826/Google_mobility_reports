{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from states import states\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import urllib.request\n",
    "import fitz\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'parsk'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'parsk '[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def correction(location, category):\n",
    "# dictionary[new_key] = dictionary.pop(old_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test3.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bad_graph_count(num, location):\n",
    "    if (num % 2) == 0:\n",
    "        num2 = num+1\n",
    "    else:\n",
    "        num2 = num-1\n",
    "    print(f'num 1 is {num} and num 2 is {num2}')\n",
    "    test = location[num]\n",
    "    test2 = location[num2]\n",
    "    counter = 0\n",
    "    for i in test:\n",
    "        if i[-1] == ' ':\n",
    "            counter +=1\n",
    "    for j in test2:\n",
    "        if j[-1] == ' ':\n",
    "            counter +=1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num 1 is 10 and num 2 is 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_graph_count(10, data[0]['Counties'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Retail & recreation ': [-0.42],\n",
       " 'Grocery & pharmacy ': [-0.12],\n",
       " 'Parks ': ['NA'],\n",
       " 'Transit stations ': ['NA'],\n",
       " 'Workplace': [-0.15],\n",
       " 'Residential ': ['NA'],\n",
       " 'Name': 'Winston County'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['Counties'][66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_stream(stream):\n",
    "    data_raw = []\n",
    "    data_transformed = []\n",
    "    rotparams = None\n",
    "    npatches = 0\n",
    "    for line in stream.splitlines():       \n",
    "        if line.endswith(\" cm\"):\n",
    "            # page 146 of https://www.adobe.com/content/dam/acom/en/devnet/pdf/pdfs/pdf_reference_archives/PDFReference.pdf\n",
    "            rotparams = list(map(float,line.split()[:-1]))\n",
    "#             print(f'paramaters are {rotparams}')\n",
    "        elif line.endswith(\" l\"):\n",
    "            x,y = list(map(float,line.split()[:2]))\n",
    "            a,b,c,d,e,f = rotparams\n",
    "            xp = a*x+c*y+e\n",
    "            yp = b*x+d*y+f\n",
    "            data_transformed.append([xp,yp])\n",
    "            data_raw.append([x,y])\n",
    "        elif line.endswith(\" m\"):\n",
    "            npatches += 1\n",
    "        else:\n",
    "            pass\n",
    "    data_raw = np.array(data_raw)\n",
    "    basex, basey = data_raw[-1]\n",
    "#     print(f'basex is {basex} and {data_raw}')\n",
    "    good = False\n",
    "    if basex == 0.:\n",
    "        data_raw[:,1] = basey - data_raw[:,1]\n",
    "        data_raw[:,1] *= 100/60.\n",
    "        data_raw = data_raw[data_raw[:,1]!=0.]\n",
    "        if npatches == 1: good = True\n",
    "    return dict(data=np.array(data_raw), npatches=npatches, good=good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states = ['Alabama', 'California']\n",
    "# s = 0\n",
    "# for state in states:\n",
    "#     p=0\n",
    "#     pages = 2\n",
    "#     doc = fitz.open(f'state_reports/{state}_Mobility_Report.pdf')\n",
    "#     goodplots = []\n",
    "#     page_plots = []\n",
    "#     page_plotsall = []\n",
    "#     allplots = []\n",
    "#     for page in range(doc.pageCount):\n",
    "#         try:\n",
    "#             page_plots.append(local_goodplot)\n",
    "#             page_plotsall.append(len(allplots))\n",
    "#         except NameError:\n",
    "#             print('nothing here')\n",
    "#         local_goodplot = []\n",
    "#         xrefs = sorted(doc.getPageXObjectList(page), key=lambda x:int(x[1].replace(\"X\",\"\")))\n",
    "# #         local_goodplot = []\n",
    "#         for i,xref in enumerate(xrefs):\n",
    "#     #         print(f'just the tip {doc.xrefStream(xref[0]).decode()}')\n",
    "#             stream = doc.xrefStream(xref[0]).decode()\n",
    "#             info = parse_stream(stream)\n",
    "#             allplots.append(info)\n",
    "#             if not info[\"good\"]: \n",
    "#                 continue\n",
    "#             else:\n",
    "#                 goodplots.append(info)\n",
    "#                 local_goodplot.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing here\n",
      "{1: 3, 2: 6, 3: 17, 4: 23, 5: 30, 6: 39, 7: 47, 8: 56, 9: 62, 10: 70, 11: 80, 12: 85, 13: 94, 14: 103, 15: 114, 16: 124, 17: 130, 18: 136, 19: 142, 20: 153, 21: 162, 22: 171, 23: 181, 24: 187, 25: 196, 26: 204, 27: 213, 28: 225, 29: 231, 30: 237, 31: 246, 32: 255, 33: 265, 34: 276, 35: 280, 36: 283}\n",
      "on page 2 and went through 6 graphs but should have 6\n",
      "retail and rec for Autauga County is legit\n",
      "retail and rec for Baldwin County is legit\n",
      "on page 3 and went through 17 graphs but should have 17\n",
      "on page 4 and went through 23 graphs but should have 23\n",
      "on page 5 and went through 30 graphs but should have 30\n",
      "retail and rec for Calhoun County is legit\n",
      "on page 6 and went through 39 graphs but should have 39\n",
      "retail and rec for Chambers County is legit\n",
      "on page 7 and went through 47 graphs but should have 47\n",
      "retail and rec for Chilton County is legit\n",
      "on page 8 and went through 56 graphs but should have 56\n",
      "on page 9 and went through 62 graphs but should have 62\n",
      "retail and rec for Coffee County is legit\n",
      "on page 10 and went through 70 graphs but should have 70\n",
      "retail and rec for Colbert County is legit\n",
      "on page 11 and went through 80 graphs but should have 80\n",
      "on page 12 and went through 85 graphs but should have 85\n",
      "retail and rec for Cullman County is legit\n",
      "on page 13 and went through 94 graphs but should have 94\n",
      "retail and rec for Dale County is legit\n",
      "retail and rec for Dallas County is legit\n",
      "on page 14 and went through 103 graphs but should have 103\n",
      "retail and rec for DeKalb County is legit\n",
      "retail and rec for Elmore County is legit\n",
      "on page 15 and went through 114 graphs but should have 114\n",
      "retail and rec for Escambia County is legit\n",
      "retail and rec for Etowah County is legit\n",
      "on page 16 and went through 124 graphs but should have 124\n",
      "on page 17 and went through 130 graphs but should have 130\n",
      "on page 18 and went through 137 graphs but should have 136\n",
      "on page 19 and went through 143 graphs but should have 142\n",
      "retail and rec for Houston County is legit\n",
      "retail and rec for Jackson County is legit\n",
      "on page 20 and went through 154 graphs but should have 153\n",
      "retail and rec for Jefferson County is legit\n",
      "on page 21 and went through 163 graphs but should have 162\n",
      "retail and rec for Lauderdale County is legit\n",
      "on page 22 and went through 172 graphs but should have 171\n",
      "retail and rec for Lee County is legit\n",
      "retail and rec for Limestone County is legit\n",
      "on page 23 and went through 182 graphs but should have 181\n",
      "on page 24 and went through 188 graphs but should have 187\n",
      "retail and rec for Madison County is legit\n",
      "on page 25 and went through 197 graphs but should have 196\n",
      "retail and rec for Marshall County is legit\n",
      "on page 26 and went through 205 graphs but should have 204\n",
      "retail and rec for Mobile County is legit\n",
      "on page 27 and went through 214 graphs but should have 213\n",
      "retail and rec for Montgomery County is legit\n",
      "retail and rec for Morgan County is legit\n",
      "on page 28 and went through 226 graphs but should have 225\n",
      "on page 29 and went through 232 graphs but should have 231\n",
      "retail and rec for Pike County is legit\n",
      "on page 30 and went through 238 graphs but should have 237\n",
      "retail and rec for Russell County is legit\n",
      "retail and rec for Shelby County is legit\n",
      "on page 31 and went through 247 graphs but should have 246\n",
      "retail and rec for St. Clair County is legit\n",
      "on page 32 and went through 256 graphs but should have 255\n",
      "retail and rec for Talladega County is legit\n",
      "retail and rec for Tallapoosa County is legit\n",
      "on page 33 and went through 266 graphs but should have 265\n",
      "retail and rec for Tuscaloosa County is legit\n",
      "retail and rec for Walker County is legit\n",
      "on page 34 and went through 277 graphs but should have 276\n",
      "on page 35 and went through 281 graphs but should have 280\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a6905d7836c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[0mp\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Counties'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Workplace'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Counties'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Workplace'\u001b[0m\u001b[1;33m]\u001b[0m             \u001b[1;33m+\u001b[0m \u001b[0mallplots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mallplots\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# repeat list x amount of times\n",
    "states = ['Alabama', 'California']\n",
    "s = 0\n",
    "for state in states:\n",
    "    p=0\n",
    "    pages = 2\n",
    "    doc = fitz.open(f'state_reports/{state}_Mobility_Report.pdf')\n",
    "    goodplots = []\n",
    "    page_plots = []\n",
    "    page_plotsall = []\n",
    "    allplots = []\n",
    "    pagelist = []\n",
    "    pagenum = 1\n",
    "    for page in range(doc.pageCount):\n",
    "        pagelist.append(pagenum)\n",
    "        pagenum +=1\n",
    "        try:\n",
    "            page_plots.append(len(local_all))\n",
    "            page_plotsall.append(len(allplots))\n",
    "        except NameError:\n",
    "            print('nothing here')\n",
    "        local_goodplot = []\n",
    "        xrefs = sorted(doc.getPageXObjectList(page), key=lambda x:int(x[1].replace(\"X\",\"\")))\n",
    "        local_all = []\n",
    "        for i,xref in enumerate(xrefs):\n",
    "    #         print(f'just the tip {doc.xrefStream(xref[0]).decode()}')\n",
    "            stream = doc.xrefStream(xref[0]).decode()\n",
    "            info = parse_stream(stream)\n",
    "#             print(info)\n",
    "            allplots.append(info)\n",
    "            local_all.append(info)\n",
    "            if not info[\"good\"]: \n",
    "                continue\n",
    "            else:\n",
    "                goodplots.append(info)\n",
    "#     print(pagelist)\n",
    "#     print(page_plots)\n",
    "#     for i, j in zip(pagelist, page_plotsall):\n",
    "#         print(f\"{i}: {j}\")\n",
    "    graphcounter = dict(zip(pagelist, page_plotsall))\n",
    "    print(graphcounter)\n",
    "    try:\n",
    "        data[s]['Retail & recreation'] = [data[s]['Retail & recreation'] + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()] \n",
    "        p +=1\n",
    "    except KeyError:\n",
    "        data[s]['Retail & recreation'] = data[s].pop('Retail & recreation ')\n",
    "    try:\n",
    "        data[s]['Grocery & pharmacy'] = [data[s]['Grocery & pharmacy'] + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()] \n",
    "        p +=1\n",
    "    except KeyError:\n",
    "        data[s]['Grocery & pharmacy'] = data[s].pop('Grocery & pharmacy ')\n",
    "    try:\n",
    "        data[s]['Parks'] = [data[s]['Parks'] + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()] \n",
    "        p +=1\n",
    "    except KeyError:\n",
    "        data[s]['Parks'] = data[s].pop('Parks ')\n",
    "    try:\n",
    "        data[s]['Transit stations'] = [data[s]['Transit stations'] + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()] \n",
    "        p +=1\n",
    "    except KeyError:\n",
    "        data[s]['Transit stations'] = data[s].pop('Transit stations ')\n",
    "    try:\n",
    "        data[s]['Workplaces'] = [data[s]['Workplaces'] + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()] \n",
    "        p +=1\n",
    "    except KeyError:\n",
    "        data[s]['Workplaces'] = data[s].pop('Workplaces ')\n",
    "    try:\n",
    "        data[s]['Residential'] = [data[s]['Residential'] + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()] \n",
    "        p +=1\n",
    "    except KeyError:\n",
    "        data[s]['Residential'] = data[s].pop('Residential ')\n",
    "    for c in range(len(data[s]['Counties'])):\n",
    "        if (c % 2) == 0:\n",
    "            print(f'on page {pages} and went through {p} graphs but should have {graphcounter[pages]}')\n",
    "            pages +=1\n",
    "        try:\n",
    "            data[s]['Counties'][c]['Retail & recreation'] = [data[s]['Counties'][c]['Retail & recreation'] \\\n",
    "            + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "            p +=1\n",
    "            print(f\"retail and rec for {data[s]['Counties'][c]['Name']} is legit\")\n",
    "        except KeyError:\n",
    "            data[s]['Counties'][c]['Retail & recreation'] = data[s]['Counties'][c].pop('Retail & recreation ')\n",
    "            if data[s]['Counties'][c]['Retail & recreation'][0] != 'NA':\n",
    "                data[s]['Counties'][c]['Retail & recreation'] = [data[s]['Counties'][c]['Retail & recreation'] \\\n",
    "                + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "                p +=1\n",
    "        try:\n",
    "            data[s]['Counties'][c]['Grocery & pharmacy'] = [data[s]['Counties'][c]['Grocery & pharmacy'] \\\n",
    "            + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "            p +=1\n",
    "        except KeyError:\n",
    "            data[s]['Counties'][c]['Grocery & pharmacy'] = data[s]['Counties'][c].pop('Grocery & pharmacy ')\n",
    "            if data[s]['Counties'][c]['Grocery & pharmacy'][0] != 'NA':\n",
    "                data[s]['Counties'][c]['Grocery & pharmacy'] = [data[s]['Counties'][c]['Grocery & pharmacy'] \\\n",
    "                + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "                p +=1\n",
    "        try:\n",
    "            data[s]['Counties'][c]['Parks'] = [data[s]['Counties'][c]['Parks'] \\\n",
    "            + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "            p +=1\n",
    "        except KeyError:\n",
    "            data[s]['Counties'][c]['Parks'] = data[s]['Counties'][c].pop('Parks ')\n",
    "            if data[s]['Counties'][c]['Parks'][0] != 'NA':\n",
    "                data[s]['Counties'][c]['Parks'] = [data[s]['Counties'][c]['Parks'] \\\n",
    "                + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "                p +=1\n",
    "        try:\n",
    "            data[s]['Counties'][c]['Transit stations'] = [data[s]['Counties'][c]['Transit stations'] \\\n",
    "            + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "            p +=1\n",
    "        except KeyError:\n",
    "            data[s]['Counties'][c]['Transit stations'] = data[s]['Counties'][c].pop('Transit stations ')\n",
    "            if data[s]['Counties'][c]['Transit stations'][0] != 'NA':\n",
    "                data[s]['Counties'][c]['Transit stations'] = [data[s]['Counties'][c]['Transit stations'] \\\n",
    "                + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "                p +=1\n",
    "        try:\n",
    "            data[s]['Counties'][c]['Workplace'] = [data[s]['Counties'][c]['Workplace'] \\\n",
    "            + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "            p +=1\n",
    "        except KeyError:\n",
    "            data[s]['Counties'][c]['Workplace'] = data[s]['Counties'][c].pop('Workplace ')\n",
    "            if data[s]['Counties'][c]['Workplace'][0] != 'NA':\n",
    "                data[s]['Counties'][c]['Workplace'] = [data[s]['Counties'][c]['Workplace'] \\\n",
    "                + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "                p +=1\n",
    "        try:\n",
    "            data[s]['Counties'][c]['Residential'] = [data[s]['Counties'][c]['Residential'] \\\n",
    "            + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "            p +=1\n",
    "        except KeyError:\n",
    "            data[s]['Counties'][c]['Residential'] = data[s]['Counties'][c].pop('Residential ')\n",
    "            if data[s]['Counties'][c]['Residential'][0] != 'NA':\n",
    "                data[s]['Counties'][c]['Residential'] = [data[s]['Counties'][c]['Residential'] \\\n",
    "                + allplots[p]['data'].transpose()[1][1:].tolist()] +[allplots[p]['data'].transpose()[0].tolist()]\n",
    "                p +=1\n",
    "    s +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(allplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['Counties'][0]['Parks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # repeat list x amount of times\n",
    "# states = ['Alabama', 'California']\n",
    "# s = 0\n",
    "# for state in states:\n",
    "#     p=0\n",
    "#     pages = 2\n",
    "#     doc = fitz.open(f'state_reports/{state}_Mobility_Report.pdf')\n",
    "#     goodplots = []\n",
    "#     page_plots = []\n",
    "#     page_plotsall = []\n",
    "#     allplots = []\n",
    "#     for page in range(doc.pageCount):\n",
    "#         try:\n",
    "#             page_plots.append(local_goodplot)\n",
    "#             page_plotsall.append(len(allplots))\n",
    "#         except NameError:\n",
    "#             print('nothing here')\n",
    "#         local_goodplot = []\n",
    "#         xrefs = sorted(doc.getPageXObjectList(page), key=lambda x:int(x[1].replace(\"X\",\"\")))\n",
    "# #         local_goodplot = []\n",
    "#         for i,xref in enumerate(xrefs):\n",
    "#     #         print(f'just the tip {doc.xrefStream(xref[0]).decode()}')\n",
    "#             stream = doc.xrefStream(xref[0]).decode()\n",
    "#     #         print(stream)\n",
    "#             info = parse_stream(stream)\n",
    "#             allplots.append(info)\n",
    "#             if not info[\"good\"]: \n",
    "#                 continue\n",
    "#             else:\n",
    "#                 goodplots.append(info)\n",
    "#                 local_goodplot.append(info)\n",
    "#     print([len(i) for i in page_plots])\n",
    "#     try:\n",
    "#         data[s]['Retail & recreation'] = [data[s]['Retail & recreation'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[s]['Retail & recreation'] = data[s].pop('Retail & recreation ')\n",
    "\n",
    "#     try:\n",
    "#         data[s]['Grocery & pharmacy'] = [data[s]['Grocery & pharmacy'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[s]['Grocery & pharmacy'] = data[s].pop('Grocery & pharmacy ')\n",
    "#     try:\n",
    "#         data[s]['Parks'] = [data[s]['Parks'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[s]['Parks'] = data[s].pop('Parks ')\n",
    "#     try:\n",
    "#         data[s]['Transit stations'] = [data[s]['Transit stations'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[s]['Transit stations'] = data[s].pop('Transit stations ')\n",
    "#     try:\n",
    "#         data[s]['Workplaces'] = [data[s]['Workplaces'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[s]['Workplaces'] = data[s].pop('Workplaces ')\n",
    "#     try:\n",
    "#         data[s]['Residential'] = [data[s]['Residential'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[s]['Residential'] = data[s].pop('Residential ')\n",
    "#     for c in range(len(data[s]['Counties'])):\n",
    "#         if (c % 2) == 0:\n",
    "#             graph_count = (12-bad_graph_count(c, data[s]['Counties']))\n",
    "#         if len(page_plots[pages]) == graph_count:\n",
    "#             print(f\"ok {data[s]['Counties'][c]['Name']} on page {pages}\")\n",
    "#         else:\n",
    "#             print(f\"we have {len(page_plots[pages])} good reads and {graph_count} good graphs for {data[s]['Counties'][c]['Name']}\")\n",
    "#         if (c % 2) != 0:\n",
    "#             pages +=1\n",
    "#         try:\n",
    "#             data[s]['Counties'][c]['Retail & recreation'] = [data[s]['Counties'][c]['Retail & recreation'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[s]['Counties'][c]['Retail & recreation'] = data[s]['Counties'][c].pop('Retail & recreation ')\n",
    "#             if data[s]['Counties'][c]['Retail & recreation'][0] != 'NA':\n",
    "#                 data[s]['Counties'][c]['Retail & recreation'] = [data[s]['Counties'][c]['Retail & recreation'] \\\n",
    "#                 + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#         try:\n",
    "#             data[s]['Counties'][c]['Grocery & pharmacy'] = [data[s]['Counties'][c]['Grocery & pharmacy'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[s]['Counties'][c]['Grocery & pharmacy'] = data[s]['Counties'][c].pop('Grocery & pharmacy ')\n",
    "#             if data[s]['Counties'][c]['Grocery & pharmacy'][0] != 'NA':\n",
    "#                 data[s]['Counties'][c]['Grocery & pharmacy'] = [data[s]['Counties'][c]['Grocery & pharmacy'] \\\n",
    "#                 + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#         try:\n",
    "#             data[s]['Counties'][c]['Parks'] = [data[s]['Counties'][c]['Parks'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[s]['Counties'][c]['Parks'] = data[s]['Counties'][c].pop('Parks ')\n",
    "#             if data[s]['Counties'][c]['Parks'][0] != 'NA':\n",
    "#                 data[s]['Counties'][c]['Parks'] = [data[s]['Counties'][c]['Parks'] \\\n",
    "#                 + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#         try:\n",
    "#             data[s]['Counties'][c]['Transit stations'] = [data[s]['Counties'][c]['Transit stations'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[s]['Counties'][c]['Transit stations'] = data[s]['Counties'][c].pop('Transit stations ')\n",
    "#             if data[s]['Counties'][c]['Transit stations'][0] != 'NA':\n",
    "#                 data[s]['Counties'][c]['Transit stations'] = [data[s]['Counties'][c]['Transit stations'] \\\n",
    "#                 + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#         try:\n",
    "#             data[s]['Counties'][c]['Workplace'] = [data[s]['Counties'][c]['Workplace'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[s]['Counties'][c]['Workplace'] = data[s]['Counties'][c].pop('Workplace ')\n",
    "#             if data[s]['Counties'][c]['Workplace'][0] != 'NA':\n",
    "#                 data[s]['Counties'][c]['Workplace'] = [data[s]['Counties'][c]['Workplace'] \\\n",
    "#                 + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#         try:\n",
    "#             data[s]['Counties'][c]['Residential'] = [data[s]['Counties'][c]['Residential'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[s]['Counties'][c]['Residential'] = data[s]['Counties'][c].pop('Residential ')\n",
    "#             if data[s]['Counties'][c]['Residential'][0] != 'NA':\n",
    "#                 data[s]['Counties'][c]['Residential'] = [data[s]['Counties'][c]['Residential'] \\\n",
    "#                 + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#     s +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['Counties'][66]['Workplace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#         data[0]['Retail & recreation'] = [data[0]['Retail & recreation'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[0]['Retail & recreation'] = data[0].pop('Retail & recreation ')\n",
    "\n",
    "#     try:\n",
    "#         data[0]['Grocery & pharmacy'] = [data[0]['Grocery & pharmacy'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[0]['Grocery & pharmacy'] = data[0].pop('Grocery & pharmacy ')\n",
    "#     try:\n",
    "#         data[0]['Parks'] = [data[0]['Parks'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[0]['Parks'] = data[0].pop('Parks ')\n",
    "#     try:\n",
    "#         data[0]['Transit stations'] = [data[0]['Transit stations'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[0]['Transit stations'] = data[0].pop('Transit stations ')\n",
    "#     try:\n",
    "#         data[0]['Workplaces'] = [data[0]['Workplaces'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[0]['Workplaces'] = data[0].pop('Workplaces ')\n",
    "#     try:\n",
    "#         data[0]['Residential'] = [data[0]['Residential'] + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()] \n",
    "#         p +=1\n",
    "#     except KeyError:\n",
    "#         data[0]['Residential'] = data[0].pop('Residential ')\n",
    "#     for c in range(len(data[0]['Counties'])):\n",
    "#         try:\n",
    "#             data[0]['Counties'][c]['Retail & recreation'] = [data[0]['Counties'][c]['Retail & recreation'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[0]['Counties'][c]['Retail & recreation'] = data[0]['Counties'][c].pop('Retail & recreation ')\n",
    "#         try:\n",
    "#             data[0]['Counties'][c]['Grocery & pharmacy'] = [data[0]['Counties'][c]['Grocery & pharmacy'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[0]['Counties'][c]['Grocery & pharmacy'] = data[0]['Counties'][c].pop('Grocery & pharmacy ')\n",
    "#         try:\n",
    "#             data[0]['Counties'][c]['Parks'] = [data[0]['Counties'][c]['Parks'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[0]['Counties'][c]['Parks'] = data[0]['Counties'][c].pop('Parks ')\n",
    "#         try:\n",
    "#             data[0]['Counties'][c]['Transit stations'] = [data[0]['Counties'][c]['Transit stations'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[0]['Counties'][c]['Transit stations'] = data[0]['Counties'][c].pop('Transit stations ')\n",
    "#         try:\n",
    "#             data[0]['Counties'][c]['Workplace'] = [data[0]['Counties'][c]['Workplace'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[0]['Counties'][c]['Workplace'] = data[0]['Counties'][c].pop('Workplace ')\n",
    "#         try:\n",
    "#             data[0]['Counties'][c]['Residential'] = [data[0]['Counties'][c]['Residential'] \\\n",
    "#             + goodplots[p]['data'].transpose()[1][1:].tolist()] +[goodplots[p]['data'].transpose()[0].tolist()]\n",
    "#             p +=1\n",
    "#         except KeyError:\n",
    "#             data[0]['Counties'][c]['Residential'] = data[0]['Counties'][c].pop('Residential ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['Counties'][11]['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0.5715847, 0.0, 0.0, 0.5715847, -0.38250732, -34.761749]\n",
    "# mult = params[0]/.8\n",
    "# new = goodplots[-2]['data'].transpose()\n",
    "new = data[1]['Counties'][14]['Workplace']\n",
    "# mult = (-30/-37.47427666666667)\n",
    "y = (new[0])\n",
    "x = new[1]\n",
    "print(y)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = goodplots[0]['data'].transpose()\n",
    "y = new[1]\n",
    "x = new[0]\n",
    "print(y)\n",
    "plt.plot(new[0],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0.5715847, 0.0, 0.0, 0.5715847, -0.38250732, -34.761749]\n",
    "\n",
    "\n",
    "params[3]+params[4]+-2.74614333 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodplots[0]['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult = params[0]/.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
